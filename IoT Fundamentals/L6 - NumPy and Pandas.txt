NumPy and Pandas
-------------------------

Data analysis can be descriptive, predictive, or prescriptive. We can use it to know what happened, what might happen,
or what to do based on what happened, or will happen.

There are a number of factors to consider when analysing data like this:
	> Volume - Quantity of data.
	> Velocity - Frequency of data.
	> Variety - Unpredictability of data.
	> Veracity - Accuracy of data.

Data can be in motion, at rest, and in use.

The core class of NumPy is the ndarray, or n-dimensional array.

It is similar to a Python list, but far more powerful, allowing for a wider range of operations.

Although everything in the array must have the same type, and the dimensions along each axis must be uniform.

It has attributes like:
	> ndim
	> shape
	> size
	> dtype
	> itemsize

We can use the "array()" method to create a Python list.



	import numpy as np

	my_array = np.array([[1, 2, 3], [4, 5, 6]])



Or, alternatively, we can create an array that starts as all zeroes:



	import numpy as np

	my_array = np.zeros(shape=(3, 3))



We can use the function "arrange()" similarly to the "range()" function, to create a range of numbers:



	import numpy as np

	zero_to_nine = np.arange(10)

	two_to_nine = np.arange(2, 10)

	zero_to_nine_even = np.arange(0, 10, 2)



The "linspace()" function can be used to create an array of evenly spaced numbers across a range or interval:



	import numpy as np

	twelve_numbers = np.linspace(0, 10, 12)



It is also possible to reshape arrays, using the "reshape()" function.



	four_by_three = twelve_numbers.reshape(4, 3)



If arrays "x" and "y" are ndarrays of the same shape, they can be used in arithmetic operations together:



	add = x + y

	sub = x - y

	prod = x * y



It is important to note that the multiplication shown above using the usually asterisk symbol is not matrix multiplication,
and would instead by element-by-element multiplication.

We should use the matrix multiplication operator, the "@" symbol, to do this.



	prod = x @ y



Array indexing and slicing works almost exactly how it does in Python, except we can also separate dimensions with commas.



	a[0, 5], a[1:3, 5]



There are also a number of other useful methods for manipulating the shape and size of the array:
	> ravel() - Flatten arrays.
	> vstack() - Stack arrays vertically.
	> hstack() - Stack arrays horizontally.

Pandas is another Python library commonly used for data analysis.

The DataFrame is the core data structure in Pandas. It is like a cross between a NumPy array and a database table.

It consists of rows of data, each of which follows a schema specified in a columnar format.



	import pandas as pd

	students = pd.DataFrame({
		'Name': ['John', 'Mary', 'Bob', 'Anne'],
		'Subject': ['Computer Science', 'Physics',
		'History', 'Business'],
		'Average exam result': [70, 80, 65, 85],
	})



There are other, more efficient ways to do this though. Rather than writing the data out manually, we can read it in from
somewhere else, such as from a database, or from a CSV file.



	import pandas as pd

	students = pd.read_csv("students.csv")




DataFrames have a number of useful methods for manipulating the stored data:
	> head()
	> tail()
	> index
	> columns
	> to_numpy()
	> describe()
	> T
	> sort_index()
	> sort_values(by="name")

We can access a column by name, or by accessing a column by index. For example:



	students["Name"]

	students.loc[0]



We can also filter rows by column:



	studets.loc[0, ["Name", "Subject"]]



DataFrames, like NumPy, also support slicing:



	students.loc[0:2, ["Name", "Subject"]]



Additionally, we can also do Boolean indexing, in a way that's a little bit like SQL queries:



	students[
		students["Average exam result"] >= 80
	]



Some important terms for data analysis include:
	> Averages
		- Mean
		- Mode
		- Median
	> Standard Deviation
	> Percentiles

Given a high-dimensional input, reduce it to low-dimensional data while minimising the amount of info lost.

Some examples include:
	> Linear discriminant analysis.
	> Principle component analysis.
	> Autoencoders.
	> Information gain.

Statistical correlation is a mathematical measure of the similarity between two variables.
	> In other words, given you know the value of the variable A, how accurately can you predict the value of B?

One measure that we can use for this is Pearson Correlation.

This uses a large and complication formula that I don't want to write out, but is surely on google somewhere.

IoT devices produce huge quantities of data, so it can be useful to know techniques like these to deal with them.

Terminology like the four "V" words, or how data can be in motion, at rest, and in use, are important.

Pandas and NumPy are the workhorses of Python data analysis. Statistical and machine learning terms are important too.



